{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProFlow: Бинарная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory input\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Imports\n",
    "from proflow.data.data_loader import DataLoader\n",
    "from proflow.automl.tabular_tasks import FlowML\n",
    "\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.dtype[int64]'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "isinstance() arg 2 must be a type or tuple of types",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [64], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m loader \u001b[39m=\u001b[39m DataLoader(\n\u001b[0;32m      2\u001b[0m     df_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../../../datasets/pochta_rf/train_dataset.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m )\n\u001b[1;32m----> 6\u001b[0m train_df, test_df \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39;49mdata_load(\n\u001b[0;32m      7\u001b[0m     data_imputer\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32md:\\dev\\proflow\\ProFlow\\examples\\..\\proflow\\data\\data_loader.py:26\u001b[0m, in \u001b[0;36mDataLoader.data_load\u001b[1;34m(self, data_imputer)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_load\u001b[39m(\n\u001b[0;32m     23\u001b[0m     \u001b[39mself\u001b[39m, \n\u001b[0;32m     24\u001b[0m     data_imputer: \u001b[39mbool\u001b[39m,\n\u001b[0;32m     25\u001b[0m ):\n\u001b[1;32m---> 26\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_types_detector()\n\u001b[0;32m     28\u001b[0m     train_df, test_df \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m     29\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf,\n\u001b[0;32m     30\u001b[0m         test_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_partition, \n\u001b[0;32m     31\u001b[0m         random_state\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed,\n\u001b[0;32m     32\u001b[0m         shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m     )\n\u001b[0;32m     35\u001b[0m     shape_table \u001b[39m=\u001b[39m PrettyTable()\n",
      "File \u001b[1;32md:\\dev\\proflow\\ProFlow\\examples\\..\\proflow\\data\\data_loader.py:79\u001b[0m, in \u001b[0;36mDataLoader._data_types_detector\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(cardinality_list) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(unique_list):\n\u001b[0;32m     77\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(columns)):\n\u001b[0;32m     78\u001b[0m         data_table\u001b[39m.\u001b[39madd_row(\n\u001b[1;32m---> 79\u001b[0m             [columns[i], cardinality_list[i], unique_list[i], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf[columns[i]]\u001b[39m.\u001b[39mdtype, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object_lenght_detector(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf[columns[i]])]\n\u001b[0;32m     80\u001b[0m         )\n\u001b[0;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe lenght of columns and data params are not equal\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\dev\\proflow\\ProFlow\\examples\\..\\proflow\\data\\data_loader.py:88\u001b[0m, in \u001b[0;36mDataLoader._object_lenght_detector\u001b[1;34m(self, col)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_object_lenght_detector\u001b[39m(\u001b[39mself\u001b[39m, col: pd\u001b[39m.\u001b[39mSeries):\n\u001b[0;32m     87\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(col\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m---> 88\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(col\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mdtype(\u001b[39mobject\u001b[39m)):\n\u001b[0;32m     89\u001b[0m         \u001b[39mreturn\u001b[39;00m (col[\u001b[39m0\u001b[39m], col[\u001b[39m100\u001b[39m], col[\u001b[39m500\u001b[39m]) \u001b[39m/\u001b[39m \u001b[39m3\u001b[39m\n\u001b[0;32m     90\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: isinstance() arg 2 must be a type or tuple of types"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(\n",
    "    df_dir=\"../../../datasets/pochta_rf/train_dataset.csv\",\n",
    "    label=\"label\",\n",
    ")\n",
    "\n",
    "train_df, test_df = loader.data_load(\n",
    "    data_imputer=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryTabularModels: dict_keys(['LogisticRegression', 'SGDClassifier'])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m flowml \u001b[39m=\u001b[39m FlowML(\n\u001b[0;32m      2\u001b[0m     task\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 5\u001b[0m flowml\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      6\u001b[0m     train_df, \n\u001b[0;32m      7\u001b[0m     test_df,\n\u001b[0;32m      8\u001b[0m     label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32md:\\dev\\proflow\\ProFlow\\examples\\..\\proflow\\automl\\tabular_tasks.py:23\u001b[0m, in \u001b[0;36mFlowML.fit\u001b[1;34m(self, train_df, test_df, label)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtask \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     22\u001b[0m     btm \u001b[39m=\u001b[39m BinaryTabularModels()\n\u001b[1;32m---> 23\u001b[0m     fitted_binary_model \u001b[39m=\u001b[39m btm\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     24\u001b[0m         train_df,\n\u001b[0;32m     25\u001b[0m         test_df,\n\u001b[0;32m     26\u001b[0m         label,\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_model \u001b[39m=\u001b[39m fitted_binary_model\n",
      "File \u001b[1;32md:\\dev\\proflow\\ProFlow\\examples\\..\\proflow\\model\\binary_tasks.py:65\u001b[0m, in \u001b[0;36mBinaryTabularModels.fit\u001b[1;34m(self, train_df, test_df, label)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[39mself\u001b[39m, \n\u001b[0;32m     60\u001b[0m     train_df: pd\u001b[39m.\u001b[39mDataFrame,\n\u001b[0;32m     61\u001b[0m     test_df: pd\u001b[39m.\u001b[39mDataFrame,\n\u001b[0;32m     62\u001b[0m     label: \u001b[39mstr\u001b[39m,\n\u001b[0;32m     63\u001b[0m ):\n\u001b[0;32m     64\u001b[0m     \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msgd_model]:\n\u001b[1;32m---> 65\u001b[0m         model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     66\u001b[0m             train_df\u001b[39m.\u001b[39;49mdrop([label], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[0;32m     67\u001b[0m             train_df[label],\n\u001b[0;32m     68\u001b[0m         )\n",
      "File \u001b[1;32md:\\dev\\envs\\proflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     _dtype \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat64, np\u001b[39m.\u001b[39mfloat32]\n\u001b[1;32m-> 1138\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1139\u001b[0m     X,\n\u001b[0;32m   1140\u001b[0m     y,\n\u001b[0;32m   1141\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1142\u001b[0m     dtype\u001b[39m=\u001b[39;49m_dtype,\n\u001b[0;32m   1143\u001b[0m     order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1144\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49msolver \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mliblinear\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msag\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39msaga\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   1145\u001b[0m )\n\u001b[0;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y)\n",
      "File \u001b[1;32md:\\dev\\envs\\proflow\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\dev\\envs\\proflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1090\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[0;32m   1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[1;32m-> 1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39;49mmulti_output, y_numeric\u001b[39m=\u001b[39;49my_numeric, estimator\u001b[39m=\u001b[39;49mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1094\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32md:\\dev\\envs\\proflow\\lib\\site-packages\\sklearn\\utils\\validation.py:1112\u001b[0m, in \u001b[0;36m_check_y\u001b[1;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1111\u001b[0m     y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 1112\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m\"\u001b[39;49m, estimator_name\u001b[39m=\u001b[39;49mestimator_name)\n\u001b[0;32m   1113\u001b[0m     _ensure_no_complex_data(y)\n\u001b[0;32m   1114\u001b[0m \u001b[39mif\u001b[39;00m y_numeric \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mO\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\dev\\envs\\proflow\\lib\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "flowml = FlowML(\n",
    "    task=\"binary\"\n",
    ")\n",
    "\n",
    "flowml.fit(\n",
    "    train_df, \n",
    "    test_df,\n",
    "    label=\"label\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('proflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f09800b36e86f400344474c9fc13039b3f84a653ae5ce28f5eb90d985e520a95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
